# Hypeloop – Brain Lift

## 1. Purpose
Hypeloop is a video-centric mobile application that leverages **direct Mux uploads**, **Firebase Authentication**, and **SwiftUI** to deliver a seamless short-video experience. Key features and objectives include:

- **Direct Video Uploads**  
  Users can record or select videos locally and securely upload them to Mux via a pre-signed URL generated by Firebase Cloud Functions.  
  Includes on-device video compression to optimize file size before upload.

- **Realtime, Swipe-Based Video Feed**  
  A **multi-direction swipe** interface powered by SwiftUI. Each direction triggers a specific action:
  - **Left** → Dislike / Skip  
  - **Right** → Like / Skip  
  - **Up** → Share  
  - **Down** → Save to profile  

- **Bloom Filter for “Seen” Videos**  
  A BloomFilter- and Firestore-based mechanism stores IDs of watched videos to avoid repeats, ensuring fresh content until you’ve truly “seen it all.”  
  *(For more on the underlying theory, see [Bloom Filter – Wikipedia](https://en.wikipedia.org/wiki/Bloom_filter)  [oai_citation_attribution:0‡en.wikipedia.org](https://en.wikipedia.org/wiki/Bloom_filter).)*

- **Profile Icons via Generative GIFs**  
  A custom Firebase Function in Node.js uses the HTML5 Canvas (via `canvas` and `gifencoder`) to produce animated GIF profile icons, stored in Firestore as base64. Each user gets a dynamic but consistently generated icon.

- **Saved Videos & Offline Downloads**  
  A dedicated “Saved Videos” tab shows bookmarked content, allowing users to download MP4s for offline access.

- **Authentication & Security**  
  Firebase Authentication (Email/Password + Apple Sign In) ensures only authorized users can upload or manage video content. Firestore rules strictly guard user data.

- **“Caught Up” Screen**  
  Once you’ve exhausted unseen videos, a special screen indicates you’re “all caught up” and offers an easy refresh button.

- **AI-Driven Story Generation & TTS**  
  A new pipeline in Cloud Functions uses GPT-based large language models to generate short stories from user-supplied keywords. It extracts keyframes, determines a visual style, and optionally creates voiceovers with OpenAI TTS. Images can be generated via Leonardo’s API for consistent styling, expanding Hypeloop beyond simple video sharing into a story-driven, AI-powered media experience.

### Scope
- **In Scope**:
  - Integration with Mux for video streaming and hosting  
  - Secure, serverless backend with Firebase Functions  
  - SwiftUI front-end with **four-direction swipe** gestures  
  - Apple Sign In and email/password authentication  
  - On-device video optimization before upload  
  - Bloom filter approach for tracking “seen” videos  
  - Generative user icons (animated GIFs) via a Cloud Function  
  - Local offline downloads of saved videos  
  - **AI-based story generation pipeline (GPT + TTS) and image rendering with Leonardo**

- **Out of Scope**:
  - Advanced video editing or FX  
  - Cross-platform UI (this project is iOS/SwiftUI only)  
  - Detailed analytics or usage insights  
  - Large-scale enterprise security beyond standard Firebase measures  

---

## 2. Experts

### Mux Integration
- **Who**: Mux and serverless specialists  
- **Focus**: Generating secure pre-signed upload URLs via Firebase Functions and ensuring stable direct uploads  
- **Why Follow**: Demonstrates a scalable approach to video hosting without building a custom media server  
- **Where**:
  - [Mux Docs](https://docs.mux.com/)  [oai_citation_attribution:1‡mux.com](https://www.mux.com/docs/core/make-api-requests)  
  - [Mux Node SDK](https://github.com/muxinc/mux-node-sdk)  [oai_citation_attribution:2‡mux.com](https://www.mux.com/docs/core/make-api-requests)

### Firebase Auth & Functions
- **Who**: Cloud services and security architects  
- **Focus**: Managing user login (Apple Sign In, email/password) and creating serverless HTTPS Callable functions for Mux logic  
- **Why Follow**: Ensures strong authentication with minimal backend overhead  
- **Where**:
  - [Firebase Authentication Docs](https://firebase.google.com/docs/auth)  [oai_citation_attribution:3‡mux.com](https://www.mux.com/docs/core/make-api-requests)  
  - [Firebase Functions Docs](https://firebase.google.com/docs/functions)  [oai_citation_attribution:4‡firebase.google.com](https://firebase.google.com/docs/functions)

> With recent expansions, these Functions also orchestrate an **AI-driven story generation workflow** (GPT-based scripting, keyframe extraction, style selection) as well as text-to-speech generation and integration with Leonardo for image or motion creation.

### SwiftUI & Gesture Design
- **Who**: iOS UX designers specializing in SwiftUI  
- **Focus**: Creating a fluid, multi-direction **swipe** interface and visually appealing layouts for short videos  
- **Why Follow**: Demonstrates advanced gesture handling and state-driven UI in modern Apple frameworks  
- **Where**:
  - [SwiftUI Tutorials by Apple](https://developer.apple.com/tutorials/swiftui)  [oai_citation_attribution:5‡mux.com](https://www.mux.com/docs/core/make-api-requests)  
  - [Swift Forums - SwiftUI](https://forums.swift.org/c/swiftui/)  [oai_citation_attribution:6‡mux.com](https://www.mux.com/docs/core/make-api-requests)

### AVKit & Video Playback
- **Who**: iOS media engineers with AVKit expertise  
- **Focus**: Handling adaptive bitrate streaming (HLS), loop playback, and system resources  
- **Why Follow**: Proper streaming design is vital for user experience and performance  
- **Where**:
  - [Apple AVKit Reference](https://developer.apple.com/documentation/avkit)  [oai_citation_attribution:7‡mux.com](https://www.mux.com/docs/core/make-api-requests)  
  - [HLS Authoring Specifications](https://developer.apple.com/documentation/http_live_streaming)  [oai_citation_attribution:8‡mux.com](https://www.mux.com/docs/core/make-api-requests)

### Generative Images & GIF Encoding
- **Who**: Canvas-based animation or creative coding specialists  
- **Focus**: Producing dynamic user icons serverlessly using Node.js + Canvas  
- **Why Follow**: Highlights a custom approach to user personalization with minimal overhead on the client side  
- **Where**:
  - [Node Canvas GitHub](https://github.com/Automattic/node-canvas)  [oai_citation_attribution:9‡mux.com](https://www.mux.com/docs/core/make-api-requests)  
  - [gifencoder GitHub](https://github.com/eugeneware/gifencoder)  [oai_citation_attribution:10‡mux.com](https://www.mux.com/docs/core/make-api-requests)

> In addition to the GIF-based profile icons, **Leonardo API** is now used to generate high-quality still images (and optional motion) for story scenes. OpenAI TTS is used for voiceover generation, extending the “generative” concept to both visuals and audio.  

---

## 3. SpikyPOVs

### Truths
- **Direct-to-Mux uploads** with pre-signed URLs reduce server complexity for large media files.  
- **Firebase serverless approach** provides high scalability with minimal hosting overhead.  
- **4-Direction Swipe** gestures offer an intuitive, compact UI to like, dislike, save, or share content.  
- **Bloom Filter** ensures users don’t see the same video twice, preventing feed redundancy.  
- **Custom generative user icons** keep the app visually unique while offloading icon creation to a Node.js function.  
- **Adaptive streaming via HLS** suits varying network speeds, improving playback experiences.  
- **Seamless SwiftUI** ensures an easily maintainable, modern codebase with a reactive data flow.  
- **Local caching & offline** features (e.g., downloaded videos, ephemeral local storage) bolster user experience in poor network conditions.  
- **AI-based story & voiceover** capabilities demonstrate how large language models and TTS can be integrated smoothly, adding narrative depth to a short-video platform.

### Myths
- **“Serverless can’t handle big video workflows.”**  
  With Mux for encoding/hosting and Firebase Functions for orchestration, the system scales efficiently without a custom media pipeline.

- **“Only standard JPEG/PNG profile images are feasible.”**  
  Animated profile icons generated on the server illustrate how we can serve advanced visuals with minimal client overhead.

- **“Swipe UI is too limiting.”**  
  SwiftUI gestures support multi-direction interactions with smooth animations, delivering a fast, immersive interface.

- **“Once you watch everything, the feed is just blank.”**  
  A “Caught Up” screen clarifies that no unseen content remains and offers a refresh approach, closing the user-experience loop.

- **“AI-driven features are too complex to integrate.”**  
  With well-structured Cloud Functions, hooking up GPT-based story generation, TTS, and image generation through Leonardo is straightforward, modular, and maintainable.

---

## 4. Knowledge Tree

### Project Architecture

#### Summary
- **Cloud Functions**  
  - Generate Mux upload URLs and handle Mux webhook events.  
  - Provide on-demand user icon generation, returning base64 GIF data.  
  - Store user metadata (icons, video references) in Firestore.  
  - **Implement an AI-driven workflow** that uses GPT for story generation, extracts keyframes, determines visual styles via Leonardo, and optionally synthesizes voiceovers with OpenAI TTS.  

- **SwiftUI Front-End**  
  - Implements a **SwipeableVideoPlayer** with 4-direction swipes for like/dislike/share/save.  
  - Displays a “Caught Up” screen when the feed is empty.  
  - Handles sign-in (Apple, Email/Password) via Firebase Auth.  
  - Optimizes video on-device using AVFoundation’s export session prior to upload.

- **BloomFilter & Seen Videos**  
  - Maintains a lightweight Bloom Filter (`BloomFilterStore`) in Firestore to track viewed video IDs.  
  - Ensures fresh content by skipping known IDs.

- **Profile Icons & Story Scenes**  
  - A Node.js function uses the `canvas` + `gifencoder` libraries to produce visually rich, generative GIFs for user icons.  
  - **Leonardo API** is leveraged to create high-quality images or short motion clips that correspond to story keyframes.  
  - **TTS** integration with OpenAI’s speech models generates audio tracks for story scenes, then uploads them to Mux for streamlined playback.

- **Video Management**  
  - A dedicated `VideoManager` fetches, preloads, and navigates the video queue.  
  - Uses `AVQueuePlayer` and `AVPlayerLooper` for smooth, looping playback.  
  - Ties in with a “Saved Videos” grid, enabling local downloads and offline viewing.

#### Sources
- **Firebase & Serverless Functions**  
  - [Firebase Functions Docs](https://firebase.google.com/docs/functions)  [oai_citation_attribution:11‡firebase.google.com](https://firebase.google.com/docs/functions)  
  - [Cloud Firestore Documentation](https://firebase.google.com/docs/firestore)  [oai_citation_attribution:12‡firebase.google.com](https://firebase.google.com/docs/storage/web/upload-files)

- **SwiftUI Architecture**  
  - [SwiftUI Tutorials by Apple](https://developer.apple.com/tutorials/swiftui)  [oai_citation_attribution:13‡mux.com](https://www.mux.com/docs/core/make-api-requests)

- **AVKit & Video Playback**  
  - [Apple AVKit Reference](https://developer.apple.com/documentation/avkit)  [oai_citation_attribution:14‡mux.com](https://www.mux.com/docs/core/make-api-requests)

- **Mux Integration**  
  - [Mux Docs](https://docs.mux.com/)  [oai_citation_attribution:15‡mux.com](https://www.mux.com/docs/core/make-api-requests)

- **Apple Sign In**  
  - [Sign in with Apple Dev Docs](https://developer.apple.com/sign-in-with-apple/)  [oai_citation_attribution:16‡mux.com](https://www.mux.com/docs/core/make-api-requests)

- **Generative GIFs**  
  - [Node Canvas GitHub](https://github.com/Automattic/node-canvas)  [oai_citation_attribution:17‡mux.com](https://www.mux.com/docs/core/make-api-requests)  
  - [gifencoder GitHub](https://github.com/eugeneware/gifencoder)  [oai_citation_attribution:18‡mux.com](https://www.mux.com/docs/core/make-api-requests)

- **Bloom Filter Fundamentals**  
  - [Bloom Filter – Wikipedia](https://en.wikipedia.org/wiki/Bloom_filter)  [oai_citation_attribution:19‡en.wikipedia.org](https://en.wikipedia.org/wiki/Bloom_filter)

- **OpenAI TTS & GPT**  
  - [OpenAI Docs](https://platform.openai.com/docs/)  [oai_citation_attribution:20‡openai.com](https://platform.openai.com/docs/)

- **Leonardo API**  
  - [Leonardo.ai Docs](https://www.leonardo.ai/)  [oai_citation_attribution:21‡leonardo.ai](https://www.leonardo.ai/)

---

> **This updated Brain Lift document reflects Hypeloop’s multi-directional swipe design, Bloom filter approach for content freshness, generative profile icons, and robust serverless architecture—showcasing how Firebase, SwiftUI, Mux, and modern AI (GPT, TTS, Leonardo) combine for a future-proof short-video platform.**